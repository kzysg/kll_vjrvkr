import time
import datetime
import re
import os
import requests
import difflib
import subprocess
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from bs4 import BeautifulSoup
from datetime import datetime
from zoneinfo import ZoneInfo  # Python 3.9+


# ãƒ•ã‚¡ã‚¤ãƒ«å
RESULT_FILE = "result_name_madori.txt"
LATEST_FILE = "latest_result.txt"

# ç’°å¢ƒå¤‰æ•°
DISCORD_WEBHOOK_URL = os.environ.get("DISCORD_WEBHOOK_URL")
GITHUB_TOKEN = os.environ.get("GITHUB_TOKEN")  # è‡ªå‹•ãƒˆãƒ¼ã‚¯ãƒ³
GITHUB_REPOSITORY = os.environ.get("GITHUB_REPOSITORY")  # user/repo

# -----------------------------------------------------
# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°è¨­å®š
# -----------------------------------------------------
URL = "https://jhomes.to-kousya.or.jp/search/jkknet/service/akiyaJyoukenStartInit"
WAIT_TIME = 10

options = Options()
options.add_argument("--headless=new")
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")
options.add_argument("--disable-gpu")

driver = webdriver.Chrome(options=options)
driver.get(URL)
time.sleep(3)

# ãƒšãƒ¼ã‚¸é·ç§»
try:
    next_link = driver.find_element(By.XPATH, "//a[contains(@onclick, 'submitNext')]")
    next_link.click()
    time.sleep(WAIT_TIME)
except:
    time.sleep(WAIT_TIME)

if len(driver.window_handles) > 1:
    driver.switch_to.window(driver.window_handles[-1])
    time.sleep(3)

#ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹æ“ä½œï¼ˆä¸–ç”°è°·åŒºãƒ»å¤§ç”°åŒºãƒ»æ¿æ©‹åŒºï¼‰
for value in ["12", "11", "19"]:
    try:
        checkbox = driver.find_element(By.CSS_SELECTOR, f'input[value="{value}"][type="checkbox"]')
        checkbox.click()
        time.sleep(0.5)
    except:
        pass

# æ¤œç´¢ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯
try:
    search_button = driver.find_element(By.XPATH, "//img[@alt='æ¤œç´¢ã™ã‚‹']/parent::a")
    search_button.click()
    time.sleep(WAIT_TIME)
except:
    pass

# HTMLå–å¾—
html = driver.page_source
driver.quit()
soup = BeautifulSoup(html, "html.parser")
with open("page_source.html", "w", encoding="utf-8") as f:
    f.write(html)

# HTMLã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
lines = []
for tr in soup.find_all("tr"):
    cols = [td.get_text(strip=True) for td in tr.find_all("td")]  # trã‚¿ã‚°ã‚’é †ã«å‡¦ç†
    if cols:
        line = "ï½œ".join(cols)  # åˆ—ã®é–“ã«ï½œã‚’å…¥ã‚Œã¦1è¡Œã«
        lines.append(line)
lines = [line for line in lines if line.strip()]  # ç©ºç™½è¡Œã‚„ä½™åˆ†ãªã‚¹ãƒšãƒ¼ã‚¹ã‚’å‰Šé™¤

# ä¿å­˜
text_path = "page_text.txt"
with open(text_path, "w", encoding="utf-8") as f:
    f.write("\n".join(lines))
print(f"ğŸ’¾ {text_path} ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ")



# çµæœå–å¾—
#results = []
#rows = soup.find_all("tr", class_=re.compile(r"ListTXT[12]"))
#for row in rows:
#    cols = [td.get_text(strip=True) for td in row.find_all("td")]
#    if len(cols) >= 10:
#        name, city, madori, yachin = cols[1], cols[2], cols[5], cols[7]
#    else:
#        continue
#    # å‹Ÿé›†ç•ªå·ãªã©
#    a_tag = row.find("a", href=re.compile(r"senPage"))
#    if a_tag and "onclick" in a_tag.attrs:
#        m = re.search(r"senPage\('','([A-Z0-9]+)','(\d+)','(\d+)'\)", a_tag["onclick"])
#        boshuNo, jyutakuCd, yusenKbn = m.groups() if m else ("", "", "")
#    else:
#        boshuNo = jyutakuCd = yusenKbn = ""
#    results.append({
#        "ä½å®…å": name,
#        "å¸‚åŒºç”ºæ‘": city,
#        "é–“å–ã‚Š": madori,
#        "å®¶è³ƒ": yachin,
#        "å‹Ÿé›†ç•ªå·": boshuNo,
#        "ä½å®…ã‚³ãƒ¼ãƒ‰": jyutakuCd,
#        "å„ªå…ˆåŒºåˆ†": yusenKbn
#    })

# -----------------------------------------------------
# æ¤œç´¢çµæœã®å–å¾—ï¼ˆæ”¹è‰¯ç‰ˆï¼š1ä»¶/è¤‡æ•°ä»¶ã©ã¡ã‚‰ã«ã‚‚å¯¾å¿œï¼‰
# -----------------------------------------------------

results = []

# ã€ŒListTXT1ã€ã¾ãŸã¯ã€ŒListTXT2ã€ã‚¯ãƒ©ã‚¹ã‚’æŒã¤ <tr> ã‚’ã™ã¹ã¦å–å¾—
rows = soup.find_all("tr", class_=re.compile(r"ListTXT[12]"))

for row in rows:
    cols = [td.get_text(strip=True) for td in row.find_all("td")]
    if len(cols) >= 10:
        name = cols[1]        # ä½å®…å
        city = cols[2]        # å¸‚åŒºç”ºæ‘
        madori = cols[5]      # é–“å–ã‚Š
        yachin = cols[7]      # å®¶è³ƒ

    # onclick="senPage('','BOSHU123','456','1')" ã®æƒ…å ±ã‚’å–å¾—
    a_tag = row.find("a", href=re.compile(r"senPage"))
    if a_tag and "onclick" in a_tag.attrs:
        m = re.search(r"senPage\('','([A-Z0-9]+)','(\d+)','(\d+)'\)", str(a_tag["onclick"]))
        if m:
            boshuNo, jyutakuCd, yusenKbn = m.groups()
        else:
            boshuNo = jyutakuCd = yusenKbn = ""
    else:
        boshuNo = jyutakuCd = yusenKbn = ""

    results.append({
        "ä½å®…å": name,
        "å¸‚åŒºç”ºæ‘": city,
        "é–“å–ã‚Š": madori,
        "å®¶è³ƒ": yachin,
        "å‹Ÿé›†ç•ªå·": boshuNo,
        "ä½å®…ã‚³ãƒ¼ãƒ‰": jyutakuCd,
        "å„ªå…ˆåŒºåˆ†": yusenKbn
    })

# rows.txt ã«ä¿å­˜
with open("rows.txt", "w", encoding="utf-8") as f:
    for row in rows:
        f.write(str(row) + "\n")  # row ã¯ Tag ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãªã®ã§æ–‡å­—åˆ—åŒ–


# result_name_madori.txt ä¿å­˜
now = datetime.now(ZoneInfo("Asia/Tokyo")).strftime("%Y-%m-%d %H:%M:%S")  # JSTã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ã‚’æŒ‡å®š
with open(RESULT_FILE, "w", encoding="utf-8") as f:
    f.write(f"å–å¾—æ—¥æ™‚: {now}\n")
    f.write(f"ç©ºãä½æˆ¸æ•°: {len(results)}ä»¶\n\n")
    f.write("ä½å®…å | å¸‚åŒºç”ºæ‘ | é–“å–ã‚Š | å®¶è³ƒ\n")
    f.write("-" * 35 + "\n")
    for r in results:
        f.write(f"{r['ä½å®…å']} | {r['å¸‚åŒºç”ºæ‘']} | {r['é–“å–ã‚Š']} | {r['å®¶è³ƒ']}\n")

print(f"ğŸ’¾ result_name_madori.txt ã« {len(results)} ä»¶ä¿å­˜ã—ã¾ã—ãŸã€‚")

# Discordé€šçŸ¥
def send_discord_message(content: str):
    if not DISCORD_WEBHOOK_URL:
        return
    data = {"content": f"ğŸ“¢ **ç©ºå®¤æƒ…å ±æ›´æ–°**\n```{content}```", "username": "jkkchecker"}
    try:
        requests.post(DISCORD_WEBHOOK_URL, json=data, timeout=10)
    except:
        pass

# ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æ­£è¦åŒ–
def read_file_normalized(path):
    if not os.path.exists(path):
        return []
    with open(path, "r", encoding="utf-8") as f:
        lines = f.read().splitlines()
    return [re.sub(r"\s+", " ", ln.replace("\u3000", " ").strip()) for ln in lines[3:]]

def read_full(path):
    if not os.path.exists(path):
        return ""
    with open(path, "r", encoding="utf-8") as f:
        return f.read()

# å·®åˆ†ãƒã‚§ãƒƒã‚¯
curr_main = read_file_normalized(RESULT_FILE)
prev_main = read_file_normalized(LATEST_FILE)

if prev_main == []:
    send_discord_message(read_full(RESULT_FILE)[:1900])
    print("ğŸ“ latest_result.txt ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚åˆå›é€šçŸ¥ã‚’è¡Œã„ã¾ã™ã€‚")
elif curr_main != prev_main:
    send_discord_message(read_full(RESULT_FILE)[:1900])
    print("ğŸ”” å·®åˆ†ã‚ã‚Šã€‚Discordã«é€šçŸ¥ã—ã¾ã™ã€‚")
else:
    print("âœ… å†…å®¹ã«å¤‰æ›´ãªã—ã€‚Discordé€šçŸ¥ã¯è¡Œã„ã¾ã›ã‚“ã€‚")


# latest_result.txt ä¸Šæ›¸ã
with open(RESULT_FILE, "r", encoding="utf-8") as src, open(LATEST_FILE, "w", encoding="utf-8") as dst:
    dst.write(src.read())

# Git commit & pushï¼ˆè‡ªå‹•ãƒˆãƒ¼ã‚¯ãƒ³å¯¾å¿œï¼‰
try:
    subprocess.run(["git", "config", "user.name", "github-actions[bot]"], check=True)
    subprocess.run(["git", "config", "user.email", "github-actions[bot]@users.noreply.github.com"], check=True)
    subprocess.run(["git", "add", LATEST_FILE], check=True)
    subprocess.run(["git", "commit", "-m", f"Update {LATEST_FILE} ({now})"], check=True)
    push_url = f"https://x-access-token:{GITHUB_TOKEN}@github.com/{GITHUB_REPOSITORY}.git"
    subprocess.run(["git", "push", push_url, "HEAD:main"], check=True)
    print(f"âœ… {LATEST_FILE} ã‚’ GitHub ã«ã‚³ãƒŸãƒƒãƒˆ & pushã—ã¾ã—ãŸ")
except subprocess.CalledProcessError:
    pass



# -----------------------------------------------------
# å‡ºåŠ›
# -----------------------------------------------------
now = datetime.now(ZoneInfo("Asia/Tokyo")).strftime("%Y-%m-%d %H:%M:%S")  # JSTã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ã‚’æŒ‡å®š
print(f"ğŸ  å®Ÿè¡Œæ™‚åˆ»: {now}")
