import time
import datetime
import re
import os
import requests
import difflib
import subprocess
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from bs4 import BeautifulSoup
from datetime import datetime
from zoneinfo import ZoneInfo  # Python 3.9+


# ãƒ•ã‚¡ã‚¤ãƒ«å
RESULT_FILE = "result_name_madori.txt"
LATEST_FILE = "latest_result.txt"

# ç’°å¢ƒå¤‰æ•°
DISCORD_WEBHOOK_URL = os.environ.get("DISCORD_WEBHOOK_URL")
GITHUB_TOKEN = os.environ.get("GITHUB_TOKEN")  # è‡ªå‹•ãƒˆãƒ¼ã‚¯ãƒ³
GITHUB_REPOSITORY = os.environ.get("GITHUB_REPOSITORY")  # user/repo

# -----------------------------------------------------
# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°è¨­å®š
# -----------------------------------------------------
URL = "https://jhomes.to-kousya.or.jp/search/jkknet/service/akiyaJyoukenStartInit"
WAIT_TIME = 10

options = Options()
options.add_argument("--headless=new")
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")
options.add_argument("--disable-gpu")

driver = webdriver.Chrome(options=options)
driver.get(URL)
time.sleep(3)

# ãƒšãƒ¼ã‚¸é·ç§»
try:
    next_link = driver.find_element(By.XPATH, "//a[contains(@onclick, 'submitNext')]")
    next_link.click()
    time.sleep(WAIT_TIME)
except:
    time.sleep(WAIT_TIME)

if len(driver.window_handles) > 1:
    driver.switch_to.window(driver.window_handles[-1])
    time.sleep(3)

# ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹æ“ä½œï¼ˆä¸–ç”°è°·åŒºãƒ»å¤§ç”°åŒºãƒ»æ¿æ©‹åŒºï¼‰
#for value in ["12", "11", "19"]:
#    try:
#        checkbox = driver.find_element(By.CSS_SELECTOR, f'input[value="{value}"][type="checkbox"]')
#        checkbox.click()
#        time.sleep(0.5)
#    except:
#        pass

# æ¤œç´¢ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯
try:
    search_button = driver.find_element(By.XPATH, "//img[@alt='æ¤œç´¢ã™ã‚‹']/parent::a")
    search_button.click()
    time.sleep(WAIT_TIME)
except:
    pass

# HTMLå–å¾—
html = driver.page_source
driver.quit()
soup = BeautifulSoup(html, "html.parser")
with open("page_source.html", "w", encoding="utf-8") as f:
    f.write(html)

results = []

# -----------------------------------------------------
# ã¾ãšè¤‡æ•°ä»¶ãƒšãƒ¼ã‚¸ã‚’æ¢ã™ï¼ˆListTXT1/2 ã® tr ãŒå­˜åœ¨ã™ã‚‹ã¨ãï¼‰
# -----------------------------------------------------
rows = soup.find_all("tr", class_=re.compile(r"ListTXT[12]"))

if rows:  # â† è¤‡æ•°ä»¶ãƒšãƒ¼ã‚¸
    for row in rows:
        cols = [td.get_text(strip=True) for td in row.find_all("td")]
        if len(cols) >= 10:
            name = cols[1]
            city = cols[2]
            madori = cols[5]
            yachin = cols[7]
        else:
            continue

        # onclick="senPage('','BOSHU123','456','1')"
        a_tag = row.find("a", href=re.compile(r"senPage"))
        boshuNo = jyutakuCd = yusenKbn = ""

        if a_tag and "onclick" in a_tag.attrs:
            m = re.search(r"senPage\('','([A-Z0-9]+)','(\d+)','(\d+)'\)", a_tag["onclick"])
            if m:
                boshuNo, jyutakuCd, yusenKbn = m.groups()

        results.append({
            "ä½å®…å": name,
            "å¸‚åŒºç”ºæ‘": city,
            "é–“å–ã‚Š": madori,
            "å®¶è³ƒ": yachin,
            "å‹Ÿé›†ç•ªå·": boshuNo,
            "ä½å®…ã‚³ãƒ¼ãƒ‰": jyutakuCd,
            "å„ªå…ˆåŒºåˆ†": yusenKbn
        })


# -----------------------------------------------------
# 1ä»¶ãƒšãƒ¼ã‚¸ï¼ˆè©³ç´°ãƒšãƒ¼ã‚¸ï¼‰ã®å ´åˆã¯ã“ã¡ã‚‰
# -----------------------------------------------------
else:
    # ä½å®…å
    name_tag = soup.find("div", class_="housename cls")
    name = name_tag.get_text(strip=True) if name_tag else ""

    # å¸‚åŒºç”ºæ‘ï¼ˆä¾‹ï¼šç¨å”å¤§å­¦å‰ã€ˆè‰åŠ æ¾åŸã€‰ ãªã© â†’ å–ã‚Œãªã„å ´åˆã‚‚ã‚ã‚‹ï¼‰
    # 1ä»¶ãƒšãƒ¼ã‚¸ã«ã¯å¸‚åŒºç”ºæ‘ãŒç„¡ã„å¯èƒ½æ€§ãŒé«˜ã„ã®ã§ç©ºæ¬„ã«ã™ã‚‹
    city = ""

    # é–“å–ã‚Šï¼ˆä¾‹ï¼š1DK, 2LDKï¼‰
    madori = ""
    kodawari = soup.find("div", class_="housing-list")
    if kodawari:
        # <li>ã«ã€Œ1DKã€ã€Œ2LDKã€ãªã©ãŒå…¥ã£ã¦ã„ã‚‹
        for li in kodawari.find_all("li"):
            text = li.get_text(strip=True)
            if re.search(r"\d[DLK]+", text):
                madori = text
                break

    # å®¶è³ƒï¼ˆä¾‹ï¼š62,300å††ï¼‰
    yachin = ""
    rent_tag = soup.find(text=re.compile(r"å††"))
    if rent_tag:
        yachin = rent_tag.strip()

    # å‹Ÿé›†ç•ªå·ãªã©
    boshuNo = jyutakuCd = yusenKbn = ""

    results.append({
        "ä½å®…å": name,
        "å¸‚åŒºç”ºæ‘": city,
        "é–“å–ã‚Š": madori,
        "å®¶è³ƒ": yachin,
        "å‹Ÿé›†ç•ªå·": boshuNo,
        "ä½å®…ã‚³ãƒ¼ãƒ‰": jyutakuCd,
        "å„ªå…ˆåŒºåˆ†": yusenKbn
    })


# result_name_madori.txt ä¿å­˜
now = datetime.now(ZoneInfo("Asia/Tokyo")).strftime("%Y-%m-%d %H:%M:%S")  # JSTã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ã‚’æŒ‡å®š
with open(RESULT_FILE, "w", encoding="utf-8") as f:
    f.write(f"å–å¾—æ—¥æ™‚: {now}\n")
    f.write(f"ç©ºãä½æˆ¸æ•°: {len(results)}ä»¶\n\n")
    f.write("ä½å®…å | å¸‚åŒºç”ºæ‘ | é–“å–ã‚Š | å®¶è³ƒ\n")
    f.write("-" * 35 + "\n")
    for r in results:
        f.write(f"{r['ä½å®…å']} | {r['å¸‚åŒºç”ºæ‘']} | {r['é–“å–ã‚Š']} | {r['å®¶è³ƒ']}\n")

print(f"ğŸ’¾ result_name_madori.txt ã« {len(results)} ä»¶ä¿å­˜ã—ã¾ã—ãŸã€‚")

# Discordé€šçŸ¥
def send_discord_message(content: str):
    if not DISCORD_WEBHOOK_URL:
        return
    data = {"content": f"ğŸ“¢ **ç©ºå®¤æƒ…å ±æ›´æ–°**\n```{content}```", "username": "jkkchecker"}
    try:
        requests.post(DISCORD_WEBHOOK_URL, json=data, timeout=10)
    except:
        pass

# ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æ­£è¦åŒ–
def read_file_normalized(path):
    if not os.path.exists(path):
        return []
    with open(path, "r", encoding="utf-8") as f:
        lines = f.read().splitlines()
    return [re.sub(r"\s+", " ", ln.replace("\u3000", " ").strip()) for ln in lines[3:]]

def read_full(path):
    if not os.path.exists(path):
        return ""
    with open(path, "r", encoding="utf-8") as f:
        return f.read()

# å·®åˆ†ãƒã‚§ãƒƒã‚¯
curr_main = read_file_normalized(RESULT_FILE)
prev_main = read_file_normalized(LATEST_FILE)

if prev_main == []:
    send_discord_message(read_full(RESULT_FILE)[:1900])
    print("ğŸ“ latest_result.txt ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚åˆå›é€šçŸ¥ã‚’è¡Œã„ã¾ã™ã€‚")
elif curr_main != prev_main:
    send_discord_message(read_full(RESULT_FILE)[:1900])
    print("ğŸ”” å·®åˆ†ã‚ã‚Šã€‚Discordã«é€šçŸ¥ã—ã¾ã™ã€‚")
else:
    print("âœ… å†…å®¹ã«å¤‰æ›´ãªã—ã€‚Discordé€šçŸ¥ã¯è¡Œã„ã¾ã›ã‚“ã€‚")


# latest_result.txt ä¸Šæ›¸ã
with open(RESULT_FILE, "r", encoding="utf-8") as src, open(LATEST_FILE, "w", encoding="utf-8") as dst:
    dst.write(src.read())

# Git commit & pushï¼ˆè‡ªå‹•ãƒˆãƒ¼ã‚¯ãƒ³å¯¾å¿œï¼‰
try:
    subprocess.run(["git", "config", "user.name", "github-actions[bot]"], check=True)
    subprocess.run(["git", "config", "user.email", "github-actions[bot]@users.noreply.github.com"], check=True)
    subprocess.run(["git", "add", LATEST_FILE], check=True)
    subprocess.run(["git", "commit", "-m", f"Update {LATEST_FILE} ({now})"], check=True)
    push_url = f"https://x-access-token:{GITHUB_TOKEN}@github.com/{GITHUB_REPOSITORY}.git"
    subprocess.run(["git", "push", push_url, "HEAD:main"], check=True)
    print(f"âœ… {LATEST_FILE} ã‚’ GitHub ã«ã‚³ãƒŸãƒƒãƒˆ & pushã—ã¾ã—ãŸ")
except subprocess.CalledProcessError:
    pass

# -----------------------------------------------------
# å‡ºåŠ›
# -----------------------------------------------------
now = datetime.now(ZoneInfo("Asia/Tokyo")).strftime("%Y-%m-%d %H:%M:%S")  # JSTã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ã‚’æŒ‡å®š
print(f"ğŸ  å®Ÿè¡Œæ™‚åˆ»: {now}")
