name: JKK Scraper (cache-safe)
concurrency:
  group: jkk-scraper
  cancel-in-progress: true

on:
  workflow_dispatch:
  # schedule:
  #   - cron: '*/5 0-15 * * *'

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          # âœ… Chrome & ChromeDriver ã‚’è‡ªå‹•ã§åŒæœŸã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
      - name: Install matching ChromeDriver
        run: |
          sudo apt update
          sudo apt install -y google-chrome-stable unzip curl
          CHROME_VERSION=$(google-chrome --version | grep -oE '[0-9]+(\.[0-9]+){3}' | cut -d '.' -f 1)
          echo "Detected Chrome major version: $CHROME_VERSION"
          DRIVER_VERSION=$(curl -s "https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json" \
            | jq -r --arg v "$CHROME_VERSION" '.versions[] | select(.version | startswith($v + ".")) | .version' | head -n 1)
          echo "Installing ChromeDriver version: $DRIVER_VERSION"
          DRIVER_URL=$(curl -s "https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json" \
            | jq -r --arg v "$DRIVER_VERSION" '.versions[] | select(.version == $v) | .downloads.chromedriver[] | select(.platform=="linux64").url')
          curl -Lo chromedriver.zip "$DRIVER_URL"
          unzip chromedriver.zip
          sudo mv chromedriver-linux64/chromedriver /usr/local/bin/
          sudo chmod +x /usr/local/bin/chromedriver
 
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install selenium beautifulsoup4 requests jq

      - name: Set Discord Webhook
        run: echo "DISCORD_WEBHOOK_URL=${{ secrets.DISCORD_WEBHOOK_URL }}" >> $GITHUB_ENV

      - name: Restore previous result cache
        id: restore-cache
        uses: actions/cache@v4
        with:
          path: previous_result.txt
          key: previous-result
          restore-keys: |
            previous-result-

      - name: Show cached previous result
        run: |
          if [ -f previous_result.txt ]; then
            echo "ğŸ“‚ previous_result.txt ãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å¾©å…ƒã•ã‚Œã¾ã—ãŸ:"
            cat previous_result.txt
          else
            echo "âš ï¸ previous_result.txt ã¯å­˜åœ¨ã—ã¾ã›ã‚“"
          fi

      - name: Cache hit info
        run: echo "Cache hit? ${{ steps.restore-cache.outputs.cache-hit }}"

      - name: Run scraper
        run: python main_scrape4.py

      - name: Upload file to artifact
        uses: actions/upload-artifact@v4
        with:
          name: previous_result
          path: previous_result.txt

  update-cache:
    runs-on: ubuntu-latest
    needs: scrape
    steps:
      - name: Download file from artifact
        uses: actions/download-artifact@v4
        with:
          name: previous_result

      - name: Save updated cache
        uses: actions/cache/save@v4
        with:
          path: previous_result.txt
          key: previous-result-${{ github.run_id }}
