name: JKK Scraper

on:
#  schedule:
#    # UTC23〜UTC23:55 → JST8〜8:55
#    - cron: '*/5 23 * * *'
#    # UTC0〜UTC12:55 → JST9〜21:55
#    - cron: '*/5 0-15 * * *'
  workflow_dispatch:  # 手動実行も可能

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
      
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    # ✅ Chrome & ChromeDriver を自動で同期インストール
    - name: Install matching ChromeDriver
      run: |
        sudo apt update
        sudo apt install -y google-chrome-stable unzip curl
        CHROME_VERSION=$(google-chrome --version | grep -oE '[0-9]+(\.[0-9]+){3}' | cut -d '.' -f 1)
        echo "Detected Chrome major version: $CHROME_VERSION"
        DRIVER_VERSION=$(curl -s "https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json" \
          | jq -r --arg v "$CHROME_VERSION" '.versions[] | select(.version | startswith($v + ".")) | .version' | head -n 1)
        echo "Installing ChromeDriver version: $DRIVER_VERSION"
        DRIVER_URL=$(curl -s "https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json" \
          | jq -r --arg v "$DRIVER_VERSION" '.versions[] | select(.version == $v) | .downloads.chromedriver[] | select(.platform=="linux64").url')
        curl -Lo chromedriver.zip "$DRIVER_URL"
        unzip chromedriver.zip
        sudo mv chromedriver-linux64/chromedriver /usr/local/bin/
        sudo chmod +x /usr/local/bin/chromedriver
 
      
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install selenium beautifulsoup4 requests jq

    - name: Set Discord Webhook
      run: echo "DISCORD_WEBHOOK_URL=${{ secrets.DISCORD_WEBHOOK_URL }}" >> $GITHUB_ENV

    # キャッシュ前回結果を取得
    - name: Restore previous result
      uses: actions/cache@v3
      id: cache-prev
      with:
        path: previous_result.txt
        key: previous-result
        
    - name: Run scraper
      run: python main_scrape4.py
      
    # 今回の結果をキャッシュに保存
    - name: Save current result to cache
      uses: actions/cache@v3
      with:
        path: previous_result.txt
        key: previous-result

    
    
