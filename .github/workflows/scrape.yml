name: JKK Scraper (with Cache Update)

on:
  # schedule:
  #   - cron: '*/5 23 * * *'
  #   - cron: '*/5 0-15 * * *'
  workflow_dispatch:

jobs:
  # ----------------------------
  # â‘  ã‚¸ãƒ§ãƒ–1ï¼šã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼‹ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
  # ----------------------------
  scrape:
    runs-on: ubuntu-latest
    outputs:
      changed: ${{ steps.scraper.outputs.changed }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install Chrome & ChromeDriver
        run: |
          sudo apt update
          sudo apt install -y google-chrome-stable unzip curl jq
          CHROME_VERSION=$(google-chrome --version | grep -oE '[0-9]+(\.[0-9]+){3}' | cut -d '.' -f 1)
          DRIVER_VERSION=$(curl -s "https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json" \
            | jq -r --arg v "$CHROME_VERSION" '.versions[] | select(.version | startswith($v + ".")) | .version' | head -n 1)
          DRIVER_URL=$(curl -s "https://googlechromelabs.github.io/chrome-for-testing/known-good-versions-with-downloads.json" \
            | jq -r --arg v "$DRIVER_VERSION" '.versions[] | select(.version == $v) | .downloads.chromedriver[] | select(.platform=="linux64").url')
          curl -Lo chromedriver.zip "$DRIVER_URL"
          unzip chromedriver.zip
          sudo mv chromedriver-linux64/chromedriver /usr/local/bin/
          sudo chmod +x /usr/local/bin/chromedriver

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install selenium beautifulsoup4 requests jq

      - name: Restore previous result cache
        id: restore-cache
        uses: actions/cache/restore@v4
        with:
          path: previous_result.txt
          key: previous-result
          restore-keys: |
            previous-result

      - name: Run scraper
        id: scraper
        run: |
          python main_scrape4.py
          echo "changed=true" >> $GITHUB_OUTPUT

      # âœ… æ¬¡ã®ã‚¸ãƒ§ãƒ–ã¸æ¸¡ã™ãŸã‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
      - name: Upload previous_result.txt
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: previous_result
          path: previous_result.txt

  # ----------------------------
  # â‘¡ ã‚¸ãƒ§ãƒ–2ï¼šã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä¸Šæ›¸ãæ›´æ–°
  # ----------------------------
  update-cache:
    runs-on: ubuntu-latest
    needs: scrape
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      # âœ… å‰ã®ã‚¸ãƒ§ãƒ–ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
      - name: Download previous_result.txt
        uses: actions/download-artifact@v4
        with:
          name: previous_result

      - name: Verify file exists
        run: |
          echo "ğŸ“„ File list:"
          ls -l
          cat previous_result.txt || echo "âš ï¸ previous_result.txt not found"

      # âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä¸Šæ›¸ãä¿å­˜
      - name: Save updated cache
        uses: actions/cache/save@v4
        with:
          path: previous_result.txt
          key: previous-result
